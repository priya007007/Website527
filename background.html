<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
        .lin {
            text-decoration: none;
            color: #fff;
        }

        a {
            color: #fff;
            text-decoration: none;
        }

        a:hover {
            color: #00A0C6;
            text-decoration: none;
            cursor: pointer;
        }

        .li {
            color: blueviolet;
            font-weight: bold;
        }
    </style>
    <link href="https://getbootstrap.com/docs/4.4/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div class="all">
        <h3 class="class11" style="background-color: rgb(8, 34, 82); padding: 10px;
        color: #fff;">
            <div style="height: 10px;"></div>
            <a href="index.html" class="lin"> Home </a> &nbsp&nbsp&nbsp&nbsp <a href="people.html" class="lin"> People
            </a> &nbsp&nbsp&nbsp&nbsp <a href="background.html" class="lin"> Background </a> &nbsp&nbsp&nbsp&nbsp <a
                href="project.html" class="lin"> Project Flow</a> &nbsp&nbsp&nbsp&nbsp
            <a href="external.html" class="lin"> External Documents &nbsp</a>
            <div style="height: 10px; "></div>
        </h3>
        <h2>Useful information to understand the project: </h2>
        <div>
            <h4> Reinforcment Learning</h4>
            <div>
             It is an area of Machine Learning. It operates on rewarding the desired output and punishing the negative output. This encourages the algorithm to earn more rewards and aim to reach an optimal value.
            </div>
            <h4>Deep Deterministic Policy Gradient.</h4>
            <div>
                DDPG is a reinforcement learning technique that combines both Q-learning and Policy gradients. DDPG
                is an actor-critic technique wherein the actor is a policy network that takes the state as input and
                outputs the exact action (continuous), instead of a probability distribution over actions. The
                critic is a Q-value network that takes in state and action as input and outputs the Q-value. DDPG is
                an “off”-policy method. DDPG is used in the continuous action setting and the “deterministic” in
                DDPG refers to the fact that the actor computes the action directly instead of a probability
                distribution over actions.
                DDPG is used in a continuous action setting and is an improvement over the vanilla actor-critic.
            </div>
            <h4>X-Plane</h4>
            <div>
                X-Plane is a flight simulation engine series to practise running the airplane in a simulation. X-Plane  provides  data  parameters  which  can  be  read  from  or  written  in  simulatorthrough  UDP  sockets.These  Data  Parameters  are  called  data  refs.The  X-Plane  APIallows the sharing of data with X-Plane as well as other plugins.  The most commonuse of the X-Plane APIs is to read data from X-Plane and change the values withinX-Plane.
                X-Plane  has  different  APIs  to  communicate  between  the  X-Plane  simulator  and  thescripts  written  to  perform  actions  on  the  airfact.We  are  using  X-Plane  Connect.TheX-Plane Connect (XPC) Toolbox is an open source research tool used to interact withthe X-Plane.
            </div>
            <h4>Figure: A look of X-Plane</h4>
            <img src="xplane-pic.png" alt="The image is not being displayed" style="height: 300px;">
            <div style ="height:10px"></div>

        </div>

    </div>
</body>

</html>